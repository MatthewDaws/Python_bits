{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian computation in Python\n",
    "\n",
    "## The case of simple linear regression\n",
    "\n",
    "Herein follows a bit of a rant about Bayesian techniques (in preference over _unthinking_ application of hypothesis testing) and a quick demo of how to use `pymc3` and `emcee`.\n",
    "\n",
    "Weapon of choice: Python 3 and Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "We start with a statistical model that we have an independent variable (or [input variable](https://en.wikipedia.org/wiki/Dependent_and_independent_variables) or predictor variable) $x$ which we know or control, and a dependent variable $y$ (or output variable or response variable) which we measure.  In simple linear regression we assume a linear, or straight line, relationship\n",
    "\n",
    "$$ y = a + bx. $$\n",
    "\n",
    "As measurement might contain noise, or because we might believe this model to be a simplification of reality, given data $(x_i)$ and $(y_i)$ we assume the actual relationship is\n",
    "\n",
    "$$ y_i = a + bx_i + \\epsilon_i $$\n",
    "\n",
    "where $(\\epsilon_i)$ are error terms.\n",
    "\n",
    "We assume that the $(\\epsilon_i)$ are _independent_ and _identically distributed_ with a normal distribution $N(0,\\sigma^2)$.  That is, the mean of the error is $0$, and the standard deviation is $\\sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data\n",
    "\n",
    "I'm going to use data from a really interesting article:\n",
    "\n",
    "\"Expectations of brilliance underlie gender distributions across academic disciplines.\" Sarah-Jane Leslie, Andrei Cimpian, Meredith Meyer, and Edward Freeland. Science, Vol. 347, Issue 6219, pp. 262-265. http://science.sciencemag.org/content/347/6219/262\n",
    "\n",
    "The \"supplement\" to the article contains tables which give data.  I have processed these into a csv file.\n",
    "\n",
    "Hat-tip: I got this reference from an [excellent blog post on the AMS website](https://blogs.ams.org/matheducation/2018/01/08/advice-for-new-doctoral-advisors/?utm_content=buffera7c38&utm_medium=social&utm_source=plus.google.com&utm_campaign=buffer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Discipline</th>\n",
       "      <th>FEM</th>\n",
       "      <th>AFR</th>\n",
       "      <th>ASI</th>\n",
       "      <th>FAB</th>\n",
       "      <th>FABW</th>\n",
       "      <th>FABM</th>\n",
       "      <th>HWOC</th>\n",
       "      <th>HWT</th>\n",
       "      <th>SELA</th>\n",
       "      <th>SELP</th>\n",
       "      <th>GRE</th>\n",
       "      <th>SYS</th>\n",
       "      <th>EMP</th>\n",
       "      <th>SvsE</th>\n",
       "      <th>SUIT</th>\n",
       "      <th>WEL</th>\n",
       "      <th>CHAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANTHROPOLOGY</td>\n",
       "      <td>59.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.05</td>\n",
       "      <td>6.95</td>\n",
       "      <td>9.25</td>\n",
       "      <td>9.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.13</td>\n",
       "      <td>5.43</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.90</td>\n",
       "      <td>5.70</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARCHAEOLOGY</td>\n",
       "      <td>52.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.81</td>\n",
       "      <td>3.72</td>\n",
       "      <td>4.03</td>\n",
       "      <td>6.77</td>\n",
       "      <td>9.33</td>\n",
       "      <td>9.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.17</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.39</td>\n",
       "      <td>4.70</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ART_HISTORY</td>\n",
       "      <td>76.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.06</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8.78</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>6.10</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.74</td>\n",
       "      <td>5.76</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASTRONOMY</td>\n",
       "      <td>29.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.13</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.49</td>\n",
       "      <td>6.40</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.31</td>\n",
       "      <td>2.29</td>\n",
       "      <td>4.03</td>\n",
       "      <td>2.01</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIOCHEMISTRY</td>\n",
       "      <td>45.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.79</td>\n",
       "      <td>4.35</td>\n",
       "      <td>5.30</td>\n",
       "      <td>7.67</td>\n",
       "      <td>7.88</td>\n",
       "      <td>7.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.28</td>\n",
       "      <td>2.93</td>\n",
       "      <td>3.34</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.41</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHEMISTRY</td>\n",
       "      <td>37.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.11</td>\n",
       "      <td>4.10</td>\n",
       "      <td>4.12</td>\n",
       "      <td>5.73</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.04</td>\n",
       "      <td>6.35</td>\n",
       "      <td>2.53</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.77</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CLASSICS</td>\n",
       "      <td>41.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.58</td>\n",
       "      <td>4.22</td>\n",
       "      <td>3.83</td>\n",
       "      <td>6.75</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.83</td>\n",
       "      <td>4.21</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.90</td>\n",
       "      <td>5.29</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COMMUNIC</td>\n",
       "      <td>64.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.68</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.38</td>\n",
       "      <td>6.80</td>\n",
       "      <td>9.16</td>\n",
       "      <td>9.21</td>\n",
       "      <td>-0.87</td>\n",
       "      <td>5.88</td>\n",
       "      <td>4.63</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.95</td>\n",
       "      <td>4.21</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COMP_LIT</td>\n",
       "      <td>60.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.28</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.45</td>\n",
       "      <td>3.03</td>\n",
       "      <td>6.83</td>\n",
       "      <td>8.78</td>\n",
       "      <td>9.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>5.86</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.97</td>\n",
       "      <td>5.56</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COMP_SCI</td>\n",
       "      <td>18.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>19.9</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.84</td>\n",
       "      <td>6.60</td>\n",
       "      <td>9.36</td>\n",
       "      <td>9.50</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>5.95</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.15</td>\n",
       "      <td>2.86</td>\n",
       "      <td>4.04</td>\n",
       "      <td>4.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EARTH_SCI</td>\n",
       "      <td>36.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.04</td>\n",
       "      <td>6.98</td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>6.17</td>\n",
       "      <td>2.34</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.44</td>\n",
       "      <td>5.15</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ECONOMICS</td>\n",
       "      <td>34.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.09</td>\n",
       "      <td>6.60</td>\n",
       "      <td>8.82</td>\n",
       "      <td>8.80</td>\n",
       "      <td>0.44</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.29</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2.48</td>\n",
       "      <td>4.31</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>69.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.12</td>\n",
       "      <td>6.67</td>\n",
       "      <td>7.80</td>\n",
       "      <td>7.95</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>5.92</td>\n",
       "      <td>4.91</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.95</td>\n",
       "      <td>6.07</td>\n",
       "      <td>3.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ENGINEERING</td>\n",
       "      <td>22.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>4.29</td>\n",
       "      <td>3.69</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.55</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.62</td>\n",
       "      <td>7.79</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>6.22</td>\n",
       "      <td>2.83</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2.85</td>\n",
       "      <td>4.17</td>\n",
       "      <td>4.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ENGLISH_LIT</td>\n",
       "      <td>62.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.59</td>\n",
       "      <td>2.64</td>\n",
       "      <td>6.67</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.23</td>\n",
       "      <td>0.51</td>\n",
       "      <td>5.93</td>\n",
       "      <td>4.77</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.74</td>\n",
       "      <td>5.36</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EVOLUTION_BIO</td>\n",
       "      <td>49.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.06</td>\n",
       "      <td>3.60</td>\n",
       "      <td>4.29</td>\n",
       "      <td>4.73</td>\n",
       "      <td>7.23</td>\n",
       "      <td>9.60</td>\n",
       "      <td>9.60</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>6.28</td>\n",
       "      <td>2.44</td>\n",
       "      <td>3.83</td>\n",
       "      <td>2.11</td>\n",
       "      <td>5.33</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.76</td>\n",
       "      <td>4.05</td>\n",
       "      <td>2.87</td>\n",
       "      <td>6.66</td>\n",
       "      <td>8.76</td>\n",
       "      <td>9.27</td>\n",
       "      <td>0.24</td>\n",
       "      <td>5.95</td>\n",
       "      <td>4.79</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.88</td>\n",
       "      <td>4.84</td>\n",
       "      <td>5.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LINGUISTICS</td>\n",
       "      <td>59.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.79</td>\n",
       "      <td>4.17</td>\n",
       "      <td>3.49</td>\n",
       "      <td>6.57</td>\n",
       "      <td>9.69</td>\n",
       "      <td>9.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.64</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.71</td>\n",
       "      <td>5.87</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MATH</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>10.3</td>\n",
       "      <td>4.67</td>\n",
       "      <td>4.40</td>\n",
       "      <td>4.74</td>\n",
       "      <td>3.72</td>\n",
       "      <td>6.45</td>\n",
       "      <td>8.28</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>6.62</td>\n",
       "      <td>1.91</td>\n",
       "      <td>4.71</td>\n",
       "      <td>2.84</td>\n",
       "      <td>4.39</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MID_EAST_STUD</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.88</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2.63</td>\n",
       "      <td>6.63</td>\n",
       "      <td>8.60</td>\n",
       "      <td>9.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.31</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.63</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MOLEC_BIO</td>\n",
       "      <td>54.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4.03</td>\n",
       "      <td>5.49</td>\n",
       "      <td>7.41</td>\n",
       "      <td>7.92</td>\n",
       "      <td>8.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.21</td>\n",
       "      <td>2.66</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.28</td>\n",
       "      <td>5.12</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MUS_TH_COM</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.45</td>\n",
       "      <td>4.68</td>\n",
       "      <td>4.28</td>\n",
       "      <td>3.22</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.60</td>\n",
       "      <td>8.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.18</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.18</td>\n",
       "      <td>3.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NEUROSCI</td>\n",
       "      <td>49.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.76</td>\n",
       "      <td>6.71</td>\n",
       "      <td>8.38</td>\n",
       "      <td>8.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.14</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.31</td>\n",
       "      <td>4.98</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PHILOSOPHY</td>\n",
       "      <td>31.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.11</td>\n",
       "      <td>5.23</td>\n",
       "      <td>5.07</td>\n",
       "      <td>2.71</td>\n",
       "      <td>5.88</td>\n",
       "      <td>9.71</td>\n",
       "      <td>9.71</td>\n",
       "      <td>1.35</td>\n",
       "      <td>6.66</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.01</td>\n",
       "      <td>2.66</td>\n",
       "      <td>3.10</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PHYSICS</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.41</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.74</td>\n",
       "      <td>7.32</td>\n",
       "      <td>7.46</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>6.45</td>\n",
       "      <td>2.48</td>\n",
       "      <td>3.97</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.84</td>\n",
       "      <td>5.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POLITICAL_SCI</td>\n",
       "      <td>43.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.71</td>\n",
       "      <td>4.07</td>\n",
       "      <td>3.60</td>\n",
       "      <td>6.68</td>\n",
       "      <td>8.82</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.44</td>\n",
       "      <td>6.11</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.16</td>\n",
       "      <td>4.23</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PSYCHOLOGY</td>\n",
       "      <td>72.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.46</td>\n",
       "      <td>3.73</td>\n",
       "      <td>3.79</td>\n",
       "      <td>6.72</td>\n",
       "      <td>9.41</td>\n",
       "      <td>9.33</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>6.15</td>\n",
       "      <td>4.72</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.05</td>\n",
       "      <td>5.47</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SOCIOLOLOGY</td>\n",
       "      <td>61.3</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.72</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.33</td>\n",
       "      <td>6.47</td>\n",
       "      <td>8.62</td>\n",
       "      <td>9.00</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>6.27</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.37</td>\n",
       "      <td>1.78</td>\n",
       "      <td>5.38</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SPANISH_LIT</td>\n",
       "      <td>59.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.14</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.23</td>\n",
       "      <td>8.33</td>\n",
       "      <td>9.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.38</td>\n",
       "      <td>4.81</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.86</td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>STATISTICS</td>\n",
       "      <td>41.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>18.4</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.65</td>\n",
       "      <td>4.49</td>\n",
       "      <td>3.71</td>\n",
       "      <td>6.14</td>\n",
       "      <td>9.00</td>\n",
       "      <td>9.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.02</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.18</td>\n",
       "      <td>4.96</td>\n",
       "      <td>4.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Discipline   FEM   AFR   ASI   FAB  FABW  FABM  HWOC   HWT  SELA  SELP  \\\n",
       "0    ANTHROPOLOGY  59.6   4.2   6.3  3.72  3.90  3.39  3.05  6.95  9.25  9.14   \n",
       "1     ARCHAEOLOGY  52.3   1.3   3.9  3.76  3.81  3.72  4.03  6.77  9.33  9.40   \n",
       "2     ART_HISTORY  76.8   1.5   8.8  4.06  4.00  4.16  2.85  6.85  8.78  9.00   \n",
       "3       ASTRONOMY  29.2   1.5   6.1  4.13  4.36  3.99  4.49  6.40  8.50  8.33   \n",
       "4    BIOCHEMISTRY  45.4   5.0  10.6  4.25  3.79  4.35  5.30  7.67  7.88  7.75   \n",
       "5       CHEMISTRY  37.8   4.3   9.6  4.11  4.10  4.12  5.73  7.51  7.00  6.86   \n",
       "6        CLASSICS  41.8   0.0   2.9  4.34  4.58  4.22  3.83  6.75  9.29  9.20   \n",
       "7        COMMUNIC  64.2   7.4   4.6  3.79  3.68  3.94  3.38  6.80  9.16  9.21   \n",
       "8        COMP_LIT  60.9   1.5   5.9  4.28  4.16  4.45  3.03  6.83  8.78  9.00   \n",
       "9        COMP_SCI  18.6   3.3  19.9  4.29  4.35  4.28  3.84  6.60  9.36  9.50   \n",
       "10      EARTH_SCI  36.2   1.7   5.4  3.76  3.35  3.92  5.04  6.98  7.00  8.00   \n",
       "11      ECONOMICS  34.4   4.0  14.7  4.37  4.14  4.44  4.09  6.60  8.82  8.80   \n",
       "12      EDUCATION  69.3  13.0   4.8  3.32  3.19  3.44  3.12  6.67  7.80  7.95   \n",
       "13    ENGINEERING  22.2   4.0  16.9  4.29  3.69  4.44  4.55  6.88  7.62  7.79   \n",
       "14    ENGLISH_LIT  62.4   1.3   5.0  4.42  4.26  4.59  2.64  6.67  9.12  9.23   \n",
       "15  EVOLUTION_BIO  49.8   0.0   3.2  4.06  3.60  4.29  4.73  7.23  9.60  9.60   \n",
       "16        HISTORY  45.0   5.2   4.0  3.90  3.76  4.05  2.87  6.66  8.76  9.27   \n",
       "17    LINGUISTICS  59.2   3.1  10.7  4.00  3.79  4.17  3.49  6.57  9.69  9.75   \n",
       "18           MATH  28.6   2.9  10.3  4.67  4.40  4.74  3.72  6.45  8.28  8.43   \n",
       "19  MID_EAST_STUD  38.1   0.0   6.4  4.11  2.88  4.52  2.63  6.63  8.60  9.33   \n",
       "20      MOLEC_BIO  54.4   4.6  10.8  3.88  3.66  4.03  5.49  7.41  7.92  8.00   \n",
       "21     MUS_TH_COM  15.8   0.0   6.7  4.45  4.68  4.28  3.22  7.00  7.60  8.27   \n",
       "22       NEUROSCI  49.4   4.3  12.9  3.83  3.76  3.98  4.76  6.71  8.38  8.80   \n",
       "23     PHILOSOPHY  31.4   2.7   3.8  5.11  5.23  5.07  2.71  5.88  9.71  9.71   \n",
       "24        PHYSICS  18.0   1.6   8.8  4.41  4.23  4.44  4.74  7.32  7.46  8.00   \n",
       "25  POLITICAL_SCI  43.1   5.7   7.4  3.94  3.71  4.07  3.60  6.68  8.82  8.95   \n",
       "26     PSYCHOLOGY  72.1   6.0   5.8  3.55  3.46  3.73  3.79  6.72  9.41  9.33   \n",
       "27    SOCIOLOLOGY  61.3   7.9   6.1  3.78  3.72  3.86  3.33  6.47  8.62  9.00   \n",
       "28    SPANISH_LIT  59.9   1.2   0.0  4.07  4.14  4.00  3.00  6.23  8.33  9.00   \n",
       "29     STATISTICS  41.6   5.4  18.4  4.12  3.65  4.49  3.71  6.14  9.00  9.20   \n",
       "\n",
       "     GRE   SYS   EMP  SvsE  SUIT   WEL  CHAL  \n",
       "0    NaN  6.13  5.43  0.70  1.90  5.70  4.70  \n",
       "1    NaN  6.17  3.38  2.78  2.39  4.70  5.43  \n",
       "2   0.31  6.10  3.97  2.14  1.74  5.76  4.69  \n",
       "3    NaN  6.31  2.29  4.03  2.01  4.80  4.94  \n",
       "4    NaN  6.28  2.93  3.34  2.38  5.41  4.07  \n",
       "5   0.04  6.35  2.53  3.82  2.77  4.45  4.88  \n",
       "6    NaN  5.83  4.21  1.63  1.90  5.29  4.50  \n",
       "7  -0.87  5.88  4.63  1.26  1.95  4.21  5.42  \n",
       "8  -0.04  5.86  4.43  1.43  1.97  5.56  3.84  \n",
       "9  -1.10  5.95  2.80  3.15  2.86  4.04  4.49  \n",
       "10 -0.03  6.17  2.34  3.82  2.44  5.15  4.44  \n",
       "11  0.44  6.12  3.29  2.83  2.48  4.31  4.04  \n",
       "12 -0.80  5.92  4.91  1.01  1.95  6.07  3.84  \n",
       "13 -0.62  6.22  2.83  3.38  2.85  4.17  4.70  \n",
       "14  0.51  5.93  4.77  1.16  1.74  5.36  4.65  \n",
       "15 -0.22  6.28  2.44  3.83  2.11  5.33  4.52  \n",
       "16  0.24  5.95  4.79  1.16  1.88  4.84  5.11  \n",
       "17   NaN  6.64  3.59  3.05  1.71  5.87  4.10  \n",
       "18  0.43  6.62  1.91  4.71  2.84  4.39  4.68  \n",
       "19   NaN  5.31  5.19  0.13  3.31  3.63  4.50  \n",
       "20   NaN  6.21  2.66  3.55  2.28  5.12  4.75  \n",
       "21   NaN  6.18  4.00  2.18  2.05  4.18  3.96  \n",
       "22   NaN  6.14  3.54  2.61  2.31  4.98  5.33  \n",
       "23  1.35  6.66  3.65  3.01  2.66  3.10  5.47  \n",
       "24  0.82  6.45  2.48  3.97  2.80  3.84  5.10  \n",
       "25  0.44  6.11  3.54  2.56  2.16  4.23  5.07  \n",
       "26 -0.54  6.15  4.72  1.43  2.05  5.47  4.83  \n",
       "27 -0.54  6.27  3.90  2.37  1.78  5.38  4.94  \n",
       "28   NaN  6.38  4.81  1.56  1.86  5.50  3.91  \n",
       "29   NaN  6.02  2.32  3.70  2.18  4.96  4.21  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.read_csv(\"input.csv\")\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This unfortunately doesn't include the indicator variable for STEM or not, so we add this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stem_lookup = {\"ANTHROPOLOGY\" : 0,\n",
    "               \"ARCHAEOLOGY\" : 0,\n",
    "               \"ART_HISTORY\" : 0,\n",
    "               \"ASTRONOMY\" : 1,\n",
    "               \"BIOCHEMISTRY\" : 1,\n",
    "               \"CHEMISTRY\" : 1,\n",
    "               \"CLASSICS\" : 0,\n",
    "               \"COMMUNIC\" : 0,\n",
    "               \"COMP_LIT\" : 0,\n",
    "               \"COMP_SCI\" : 1,\n",
    "               \"EARTH_SCI\" : 1,\n",
    "               \"ECONOMICS\" : 0,\n",
    "               \"EDUCATION\" : 0,\n",
    "               \"ENGINEERING\" : 1,\n",
    "               \"ENGLISH_LIT\" : 0,\n",
    "               \"EVOLUTION_BIO\" : 1,\n",
    "               \"HISTORY\" : 0,\n",
    "               \"LINGUISTICS\" : 0,\n",
    "               \"MATH\" : 1,\n",
    "               \"MID_EAST_STUD\" : 0,\n",
    "               \"MOLEC_BIO\" : 1,\n",
    "               \"MUS_TH_COM\" : 0,\n",
    "               \"NEUROSCI\" : 1,\n",
    "               \"PHILOSOPHY\" : 0,\n",
    "               \"PHYSICS\" : 1,\n",
    "               \"POLITICAL_SCI\" : 0,\n",
    "               \"PSYCHOLOGY\" : 0,\n",
    "               \"SOCIOLOLOGY\" : 0,\n",
    "               \"SPANISH_LIT\" : 0,\n",
    "               \"STATISTICS\" : 1\n",
    "              }\n",
    "\n",
    "frame[\"STEM\"] = frame[\"Discipline\"].map(lambda x : stem_lookup[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check counts\n",
    "assert sum(frame[\"STEM\"]==0), sum(frame[\"STEM\"]==1) == (18, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save out for later\n",
    "frame.to_csv(\"with_stem.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard regression\n",
    "\n",
    "We wonder how much the STEM indicator can explain \"FEM\", the % of PhD recipients who are female (2011 NSF survey).  For future reference, here is the table from the paper:\n",
    "\n",
    "![table](table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by using `scipy` which comes \"in the box\" with Anaconda.  We can recompute the `t` value (from Model 1 in the table) but we cannot find $\\beta$ yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=-16.711111111111109, intercept=52.644444444444439, rvalue=-0.49712337391743616, pvalue=0.0051931306098459088, stderr=5.512157878700302)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = scipy.stats.linregress(frame[\"STEM\"], frame[\"FEM\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0316822338643501"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvalue = np.sqrt(30-2) * result.rvalue / np.sqrt(1 - result.rvalue**2)\n",
    "tvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Standardized Coefficients\n",
    "\n",
    "See [Wikipedia](https://en.wikipedia.org/wiki/Standardized_coefficient).  Some trial + error and searching lead to this, which seems to now correctly reproduce the values from the 1st column of Table 1 in the article.\n",
    "\n",
    "Essentially, both the dependent and independent variables are first \"standardised\" (translated and scaled to have 0 mean and unit variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=-0.49712337391743627, intercept=3.0543907963232205e-16, rvalue=-0.49712337391743627, pvalue=0.0051931306098458915, stderr=0.16397608178208548)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem = frame[\"STEM\"].values\n",
    "fem = frame[\"FEM\"].values\n",
    "\n",
    "stem = (stem - np.mean(stem)) / np.std(stem)\n",
    "fem = (fem - np.mean(fem)) / np.std(fem)\n",
    "result = scipy.stats.linregress(stem, fem)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as the `zscore` method from `scipy.stats` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=-0.49712337391743627, intercept=3.0543907963232205e-16, rvalue=-0.49712337391743627, pvalue=0.0051931306098458915, stderr=0.16397608178208548)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.mstats import zscore\n",
    "\n",
    "stem = zscore(frame[\"STEM\"])\n",
    "fem = zscore(frame[\"FEM\"])\n",
    "result = scipy.stats.linregress(stem, fem)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.031682233864351"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvalue = np.sqrt(30-2) * result.rvalue / np.sqrt(1 - result.rvalue**2)\n",
    "tvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With `statsmodels`\n",
    "\n",
    "An alternative and very powerful tool is the `statsmodels` package for Python.\n",
    "\n",
    "- Install via `conda install statsmodels`\n",
    "- An \"R-like\" interface.\n",
    "- See [the docs](http://www.statsmodels.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>FEM</td>       <th>  R-squared:         </th> <td>   0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Jan 2018</td> <th>  Prob (F-statistic):</th>  <td>0.00519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:39</td>     <th>  Log-Likelihood:    </th> <td> -122.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   248.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   251.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   52.6444</td> <td>    3.486</td> <td>   15.101</td> <td> 0.000</td> <td>   45.503</td> <td>   59.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STEM</th>      <td>  -16.7111</td> <td>    5.512</td> <td>   -3.032</td> <td> 0.005</td> <td>  -28.002</td> <td>   -5.420</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.528</td> <th>  Durbin-Watson:     </th> <td>   2.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.466</td> <th>  Jarque-Bera (JB):  </th> <td>   1.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.484</td> <th>  Prob(JB):          </th> <td>   0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.608</td> <th>  Cond. No.          </th> <td>    2.45</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    FEM   R-squared:                       0.247\n",
       "Model:                            OLS   Adj. R-squared:                  0.220\n",
       "Method:                 Least Squares   F-statistic:                     9.191\n",
       "Date:                Wed, 10 Jan 2018   Prob (F-statistic):            0.00519\n",
       "Time:                        15:22:39   Log-Likelihood:                -122.35\n",
       "No. Observations:                  30   AIC:                             248.7\n",
       "Df Residuals:                      28   BIC:                             251.5\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     52.6444      3.486     15.101      0.000      45.503      59.786\n",
       "STEM         -16.7111      5.512     -3.032      0.005     -28.002      -5.420\n",
       "==============================================================================\n",
       "Omnibus:                        1.528   Durbin-Watson:                   2.687\n",
       "Prob(Omnibus):                  0.466   Jarque-Bera (JB):                1.366\n",
       "Skew:                          -0.484   Prob(JB):                        0.505\n",
       "Kurtosis:                       2.608   Cond. No.                         2.45\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = smf.ols('FEM ~ STEM', data=frame).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With standardised coefficients, and using the less-R-like interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Jan 2018</td> <th>  Prob (F-statistic):</th>  <td>0.00519</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:39</td>     <th>  Log-Likelihood:    </th> <td> -38.310</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   80.62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   83.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 3.331e-16</td> <td>    0.164</td> <td> 2.03e-15</td> <td> 1.000</td> <td>   -0.336</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.4971</td> <td>    0.164</td> <td>   -3.032</td> <td> 0.005</td> <td>   -0.833</td> <td>   -0.161</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.528</td> <th>  Durbin-Watson:     </th> <td>   2.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.466</td> <th>  Jarque-Bera (JB):  </th> <td>   1.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.484</td> <th>  Prob(JB):          </th> <td>   0.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.608</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.247\n",
       "Model:                            OLS   Adj. R-squared:                  0.220\n",
       "Method:                 Least Squares   F-statistic:                     9.191\n",
       "Date:                Wed, 10 Jan 2018   Prob (F-statistic):            0.00519\n",
       "Time:                        15:22:39   Log-Likelihood:                -38.310\n",
       "No. Observations:                  30   AIC:                             80.62\n",
       "Df Residuals:                      28   BIC:                             83.42\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       3.331e-16      0.164   2.03e-15      1.000      -0.336       0.336\n",
       "x1            -0.4971      0.164     -3.032      0.005      -0.833      -0.161\n",
       "==============================================================================\n",
       "Omnibus:                        1.528   Durbin-Watson:                   2.687\n",
       "Prob(Omnibus):                  0.466   Jarque-Bera (JB):                1.366\n",
       "Skew:                          -0.484   Prob(JB):                        0.505\n",
       "Kurtosis:                       2.608   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem = zscore(frame[\"STEM\"])\n",
    "stem = sm.add_constant(stem)\n",
    "fem = zscore(frame[\"FEM\"])\n",
    "\n",
    "result = sm.OLS(fem, stem).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics rant\n",
    "\n",
    "So, we see that we get $p=0.005$, so this is \"good\", right?\n",
    "\n",
    "First, let's plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3e9c14df60>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAFpCAYAAACVjP/1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e9c1c4ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.scatter(zscore(frame[\"STEM\"]), zscore(frame[\"FEM\"]))\n",
    "\n",
    "a, b = result.params\n",
    "x = np.linspace(-1, 1.5, 100)\n",
    "y = a + b * x\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a terribly compelling _linear_ relationship...\n",
    "\n",
    "The formal _hypothesis test_ that we are actually carrying out here is to test:\n",
    "\n",
    "$$ H_0 : \\beta = 0  \\quad\\text{against}\\quad H_1 : \\beta\\not=0 $$\n",
    "\n",
    "If $H_0$ were true (and the model were true) then $t$ would be distributed as a [t distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) with $n-2$ degrees of freedom ($n$ is the number of observations, so here $n=30$).  We use a two-tailed distribution, so the following code reproduces the $p$-value we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0051931306098458915"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdist = scipy.stats.t(28)\n",
    "tdist.cdf(-3.031682233864351) * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to stress that the following is the _correct_ interpretation of this $p$-value:\n",
    "\n",
    "> Assume that the data really satisfies the model $x_i = a + e_i$ where $e_i$ are idd $N(0,\\sigma^2)$ error terms.  That is, $H_0$ really does hold.  Then the probability of seeing data \"as extreme\" as the data we have is 0.005.\n",
    "\n",
    "So we reject $H_0$ because seeing such data by chance, if the data really came from $H_0$, is very small.  Notice that this says nothing about $H_1$, and says rather little about what the \"real\" value of $\\beta$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding further parameters\n",
    "\n",
    "\"Model 2\" in the paper adds the FEM (Field-specific ability beliefs) variable in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>FEM</td>       <th>  R-squared:         </th> <td>   0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>3.06e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:22:39</td>     <th>  Log-Likelihood:    </th> <td> -115.06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   236.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    27</td>      <th>  BIC:               </th> <td>   240.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  157.2384</td> <td>   25.592</td> <td>    6.144</td> <td> 0.000</td> <td>  104.729</td> <td>  209.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STEM</th>      <td>  -14.2314</td> <td>    4.443</td> <td>   -3.203</td> <td> 0.003</td> <td>  -23.348</td> <td>   -5.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FAB</th>       <td>  -25.8009</td> <td>    6.275</td> <td>   -4.111</td> <td> 0.000</td> <td>  -38.677</td> <td>  -12.925</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.014</td> <th>  Durbin-Watson:     </th> <td>   2.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.993</td> <th>  Jarque-Bera (JB):  </th> <td>   0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.044</td> <th>  Prob(JB):          </th> <td>   0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.651</td> <th>  Cond. No.          </th> <td>    51.9</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    FEM   R-squared:                       0.537\n",
       "Model:                            OLS   Adj. R-squared:                  0.503\n",
       "Method:                 Least Squares   F-statistic:                     15.66\n",
       "Date:                Wed, 10 Jan 2018   Prob (F-statistic):           3.06e-05\n",
       "Time:                        15:22:39   Log-Likelihood:                -115.06\n",
       "No. Observations:                  30   AIC:                             236.1\n",
       "Df Residuals:                      27   BIC:                             240.3\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    157.2384     25.592      6.144      0.000     104.729     209.748\n",
       "STEM         -14.2314      4.443     -3.203      0.003     -23.348      -5.115\n",
       "FAB          -25.8009      6.275     -4.111      0.000     -38.677     -12.925\n",
       "==============================================================================\n",
       "Omnibus:                        0.014   Durbin-Watson:                   2.538\n",
       "Prob(Omnibus):                  0.993   Jarque-Bera (JB):                0.161\n",
       "Skew:                          -0.044   Prob(JB):                        0.922\n",
       "Kurtosis:                       2.651   Cond. No.                         51.9\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = smf.ols('FEM ~ STEM + FAB', data=frame).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it seems that we need to standardise the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.504</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   16.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>2.08e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:23:37</td>     <th>  Log-Likelihood:    </th> <td> -31.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   66.04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   68.84</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.4234</td> <td>    0.130</td> <td>   -3.262</td> <td> 0.003</td> <td>   -0.689</td> <td>   -0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>   -0.5434</td> <td>    0.130</td> <td>   -4.187</td> <td> 0.000</td> <td>   -0.809</td> <td>   -0.278</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.014</td> <th>  Durbin-Watson:     </th> <td>   2.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.993</td> <th>  Jarque-Bera (JB):  </th> <td>   0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.044</td> <th>  Prob(JB):          </th> <td>   0.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.651</td> <th>  Cond. No.          </th> <td>    1.15</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.537\n",
       "Model:                            OLS   Adj. R-squared:                  0.504\n",
       "Method:                 Least Squares   F-statistic:                     16.24\n",
       "Date:                Wed, 10 Jan 2018   Prob (F-statistic):           2.08e-05\n",
       "Time:                        15:23:37   Log-Likelihood:                -31.018\n",
       "No. Observations:                  30   AIC:                             66.04\n",
       "Df Residuals:                      28   BIC:                             68.84\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.4234      0.130     -3.262      0.003      -0.689      -0.157\n",
       "x2            -0.5434      0.130     -4.187      0.000      -0.809      -0.278\n",
       "==============================================================================\n",
       "Omnibus:                        0.014   Durbin-Watson:                   2.538\n",
       "Prob(Omnibus):                  0.993   Jarque-Bera (JB):                0.161\n",
       "Skew:                          -0.044   Prob(JB):                        0.922\n",
       "Kurtosis:                       2.651   Cond. No.                         1.15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray([zscore(frame[\"STEM\"]), zscore(frame[\"FAB\"])]).T\n",
    "y = zscore(frame[\"FEM\"])\n",
    "result = sm.OLS(y, x).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted coefficients, and $p$-values, and $R^2$, are all the same as the paper.  The $t$ values are slightly different..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the rest while we're here\n",
    "\n",
    "We now recreate Models 3, 4 and 5.  Again, the fitted coefficients match, but the $t$ and $p$ values don't quite match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.56</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>9.07e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:29:09</td>     <th>  Log-Likelihood:    </th> <td> -30.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   67.85</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    27</td>      <th>  BIC:               </th> <td>   72.06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.3480</td> <td>    0.228</td> <td>   -1.529</td> <td> 0.138</td> <td>   -0.815</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>   -0.5620</td> <td>    0.140</td> <td>   -4.028</td> <td> 0.000</td> <td>   -0.848</td> <td>   -0.276</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>   -0.0919</td> <td>    0.226</td> <td>   -0.406</td> <td> 0.688</td> <td>   -0.557</td> <td>    0.373</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.061</td> <th>  Durbin-Watson:     </th> <td>   2.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.970</td> <th>  Jarque-Bera (JB):  </th> <td>   0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.078</td> <th>  Prob(JB):          </th> <td>   0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.585</td> <th>  Cond. No.          </th> <td>    3.19</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.540\n",
       "Model:                            OLS   Adj. R-squared:                  0.489\n",
       "Method:                 Least Squares   F-statistic:                     10.56\n",
       "Date:                Wed, 10 Jan 2018   Prob (F-statistic):           9.07e-05\n",
       "Time:                        15:29:09   Log-Likelihood:                -30.926\n",
       "No. Observations:                  30   AIC:                             67.85\n",
       "Df Residuals:                      27   BIC:                             72.06\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.3480      0.228     -1.529      0.138      -0.815       0.119\n",
       "x2            -0.5620      0.140     -4.028      0.000      -0.848      -0.276\n",
       "x3            -0.0919      0.226     -0.406      0.688      -0.557       0.373\n",
       "==============================================================================\n",
       "Omnibus:                        0.061   Durbin-Watson:                   2.577\n",
       "Prob(Omnibus):                  0.970   Jarque-Bera (JB):                0.245\n",
       "Skew:                          -0.078   Prob(JB):                        0.885\n",
       "Kurtosis:                       2.585   Cond. No.                         3.19\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray([zscore(frame[\"STEM\"]), zscore(frame[\"FAB\"]), zscore(frame[\"HWOC\"])]).T\n",
    "y = zscore(frame[\"FEM\"])\n",
    "result = sm.OLS(y, x).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.581</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>0.000106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:31:21</td>     <th>  Log-Likelihood:    </th> <td> -29.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   67.06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    26</td>      <th>  BIC:               </th> <td>   72.67</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.3051</td> <td>    0.223</td> <td>   -1.368</td> <td> 0.183</td> <td>   -0.764</td> <td>    0.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>   -0.5762</td> <td>    0.136</td> <td>   -4.236</td> <td> 0.000</td> <td>   -0.856</td> <td>   -0.297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>   -0.0052</td> <td>    0.227</td> <td>   -0.023</td> <td> 0.982</td> <td>   -0.472</td> <td>    0.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.2375</td> <td>    0.149</td> <td>    1.592</td> <td> 0.123</td> <td>   -0.069</td> <td>    0.544</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.329</td> <th>  Durbin-Watson:     </th> <td>   2.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.848</td> <th>  Jarque-Bera (JB):  </th> <td>   0.439</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.215</td> <th>  Prob(JB):          </th> <td>   0.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.591</td> <th>  Cond. No.          </th> <td>    3.53</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.581\n",
       "Model:                            OLS   Adj. R-squared:                  0.516\n",
       "Method:                 Least Squares   F-statistic:                     9.002\n",
       "Date:                Wed, 10 Jan 2018   Prob (F-statistic):           0.000106\n",
       "Time:                        15:31:21   Log-Likelihood:                -29.531\n",
       "No. Observations:                  30   AIC:                             67.06\n",
       "Df Residuals:                      26   BIC:                             72.67\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.3051      0.223     -1.368      0.183      -0.764       0.153\n",
       "x2            -0.5762      0.136     -4.236      0.000      -0.856      -0.297\n",
       "x3            -0.0052      0.227     -0.023      0.982      -0.472       0.461\n",
       "x4             0.2375      0.149      1.592      0.123      -0.069       0.544\n",
       "==============================================================================\n",
       "Omnibus:                        0.329   Durbin-Watson:                   2.722\n",
       "Prob(Omnibus):                  0.848   Jarque-Bera (JB):                0.439\n",
       "Skew:                           0.215   Prob(JB):                        0.803\n",
       "Kurtosis:                       2.591   Cond. No.                         3.53\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray([zscore(frame[\"STEM\"]), zscore(frame[\"FAB\"]), zscore(frame[\"HWOC\"]), zscore(frame[\"SELA\"])]).T\n",
    "y = zscore(frame[\"FEM\"])\n",
    "result = sm.OLS(y, x).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.498</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Jan 2018</td> <th>  Prob (F-statistic):</th> <td>0.000342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:32:09</td>     <th>  Log-Likelihood:    </th> <td> -29.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   68.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    25</td>      <th>  BIC:               </th> <td>   76.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.2772</td> <td>    0.255</td> <td>   -1.088</td> <td> 0.287</td> <td>   -0.802</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>   -0.5573</td> <td>    0.159</td> <td>   -3.509</td> <td> 0.002</td> <td>   -0.884</td> <td>   -0.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.0205</td> <td>    0.254</td> <td>    0.081</td> <td> 0.936</td> <td>   -0.503</td> <td>    0.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.2440</td> <td>    0.154</td> <td>    1.582</td> <td> 0.126</td> <td>   -0.074</td> <td>    0.562</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>   -0.0608</td> <td>    0.250</td> <td>   -0.243</td> <td> 0.810</td> <td>   -0.576</td> <td>    0.455</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.276</td> <th>  Durbin-Watson:     </th> <td>   2.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.871</td> <th>  Jarque-Bera (JB):  </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.201</td> <th>  Prob(JB):          </th> <td>   0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.634</td> <th>  Cond. No.          </th> <td>    4.15</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.582\n",
       "Model:                            OLS   Adj. R-squared:                  0.498\n",
       "Method:                 Least Squares   F-statistic:                     6.953\n",
       "Date:                Wed, 10 Jan 2018   Prob (F-statistic):           0.000342\n",
       "Time:                        15:32:09   Log-Likelihood:                -29.495\n",
       "No. Observations:                  30   AIC:                             68.99\n",
       "Df Residuals:                      25   BIC:                             76.00\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.2772      0.255     -1.088      0.287      -0.802       0.247\n",
       "x2            -0.5573      0.159     -3.509      0.002      -0.884      -0.230\n",
       "x3             0.0205      0.254      0.081      0.936      -0.503       0.544\n",
       "x4             0.2440      0.154      1.582      0.126      -0.074       0.562\n",
       "x5            -0.0608      0.250     -0.243      0.810      -0.576       0.455\n",
       "==============================================================================\n",
       "Omnibus:                        0.276   Durbin-Watson:                   2.726\n",
       "Prob(Omnibus):                  0.871   Jarque-Bera (JB):                0.369\n",
       "Skew:                           0.201   Prob(JB):                        0.832\n",
       "Kurtosis:                       2.634   Cond. No.                         4.15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.asarray([zscore(frame[\"STEM\"]), zscore(frame[\"FAB\"]), zscore(frame[\"HWOC\"]),\n",
    "                zscore(frame[\"SELA\"]), zscore(frame[\"SvsE\"])]).T\n",
    "y = zscore(frame[\"FEM\"])\n",
    "result = sm.OLS(y, x).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
